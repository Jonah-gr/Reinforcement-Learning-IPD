\chapter{Einleitung}

\section{Thema und Motivation}
Das Iterative Gefangenendilemma (IPD) ist ein klassisches Problem der Spieltheorie, 
das die Herausforderungen von Kooperation und Eigennutz modelliert. 
Zwei Spieler müssen unabhängig voneinander entscheiden, ob sie kooperieren oder 
defektieren. Während Kooperation zu einem besseren kollektiven Ergebnis führt, 
ist aus individueller Sicht Verrat (Defektion) oft vorteilhafter -- ein klassisches Dilemma.
In der Realität tauchen ähnliche Dilemmata in vielen Bereichen auf, etwa in der 
Wirtschaft, der Politik und der Evolutionsbiologie. Ein zentrales Forschungsthema 
ist, ob und unter welchen Bedingungen Akteure langfristig kooperative Strategien 
entwickeln können, um dem Dilemma zu entkommen.

Mit der zunehmenden Bedeutung von künstlicher Intelligenz (KI) und Reinforcement 
Learning (RL) stellt sich die Frage, wie sich autonome Agenten in einem solchen 
Szenario verhalten. 
% Ziel dieses Projekts ist es, 
% RL-Agenten im IPD zu trainieren und zu analysieren, ob sie fähig sind, Strategien 
% zu entwickeln, die über bloßen Eigennutz hinausgehen. Damit trägt diese Arbeit zur 
% Diskussion über das Potenzial von RL in sozialen und spieltheoretischen Kontexten 
% bei.

\section{Ziele der Arbeit}
Das Ziel dieser Arbeit ist es, zu untersuchen, wie sich RL-Agenten im IPD verhalten
und ob sie in der Lage sind, kooperative Strategien zu entwickeln. Dabei stehen 
folgende zentrale Forschungsfragen im Fokus:
\begin{enumerate}
    \item Können RL-Agenten lernen, langfristig zu kooperieren?
        \begin{itemize}
            \item Entwickeln sie Strategien, die über reines Eigeninteresse hinausgehen?
        \end{itemize}
    \item Welche Strategien entstehen im Laufe des Lernprozesses?
        \begin{itemize}
            \item Verhalten sich die Agenten wie bekannte spieltheoretische Strategien (z. B. ''Tit-for-Tat'' oder ''Always Defect'')?
            \item Zeigen sich neuartige, unerwartete Verhaltensmuster?
        \end{itemize}

\end{enumerate}
Um diese Fragen zu beantworten, werden verschiedene RL-Algorithmen auf das IPD 
angewendet, die Trainingsverläufe analysiert und die resultierenden Strategien 
miteinander verglichen. Durch die gewonnenen Erkenntnisse soll ein tieferes Verständnis 
dafür geschaffen werden, wie lernende Agenten spieltheoretische Herausforderungen 
bewältigen und ob sie sich aus dem klassischen Dilemma befreien können.